{"title":"Time Series - Midterm Project","markdown":{"yaml":{"title":"Time Series - Midterm Project","subtitle":"Residential Real Estate Financing Patterns: Insights from Mortgage Averages","author":"By - Sree Lekshmi Prasannan <br> Jaskirat Singh","format":"revealjs","editor":"source","toc":true,"toc-depth":1,"slide-number":true,"smaller":false,"scrollable":true,"editor_options":{"chunk_output_type":"console"},"output-dir":"docs"},"headingText":"Set up chunk for all slides","containsRefs":false,"markdown":"\n\n\n```{r, include=FALSE}\nlibrary(forecast)\nlibrary(fpp3)\nlibrary(tidyverse)\nlibrary(tsbox)\nlibrary(zoo)\nlibrary(seasonal)\nlibrary(astsa)\nlibrary(patchwork)\nlibrary(tseries)\nlibrary(fredr)\nlibrary(quarto)\nlibrary(xts)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(vars)\n\n```\n\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(\n  echo = TRUE,\n  message = FALSE,\n  warning = FALSE,\n  cache = TRUE,\n  dev.args = list(pointsize = 11)\n)\n```\n\n\n# Dataset\n\n## Time Series used in the project - \n- Real Estate Loans: \"Residential Real Estate Loans, All Commercial Banks\" from FRED which represents the total amount of residential real estate loans issued by all commercial banks in the United States.\n- The covariate series used is \"30-Year Fixed Rate Mortgage Average\" which represents the average interest rate on 30-year fixed-rate mortgages in the United States\n\n## Relevance - \n- The average interest rate on 30-year fixed-rate mortgages is a crucial factor influencing the affordability of home purchases and the demand for mortgage financing.\n- By analyzing trends in the fixed-rate mortgage average, we can gain insights into shifts in mortgage interest rates, which in turn can influence housing market activity, including home sales, and overall residential real estate lending.\n\n\n## Basic statistics about datasets - \n\n```{r, echo=FALSE}\n#| output-location: slide\n# Reading Real Estate Loans data and the covariate series Mortgage Rate\nfredr_set_key(\"4e2b405e7ea0d612c659d24c185134a1\")\n\nreal_estate_loans <- fredr(series_id = \"RREACBW027NBOG\")\nmortgage_rate <- fredr(series_id = \"MORTGAGE30US\")\n\n# Taking date and value column from booth the series\nreal_estate_loans <- real_estate_loans[c(\"date\", \"value\")]\nmortgage_rate <- mortgage_rate[c(\"date\", \"value\")]\n\n\n# Converting date column in both the series to date type\nreal_estate_loans$date <- as.Date(real_estate_loans$date)\nmortgage_rate$date <- as.Date(mortgage_rate$date)\n\ncat(\"- Both time series are on weekly basis and not seasonally adjusted.\\n\")\ncat(\"- Total number of rows in real estate loans dataset:\", nrow(real_estate_loans), \"\\n\")\ncat(\"- Total number of rows in mortgage rate dataset:\", nrow(mortgage_rate), \"\\n\\n\")\n\n# Basic summary statistics\ncat(\"- Summary of real estate loans dataset:\", \"\\n\")\nsummary(real_estate_loans)\n\ncat(\"- Summary of mortgage rate dataset:\", \"\\n\")\nsummary(mortgage_rate)\ncat(\"\\n\\n\")\n\n\n\n```\n\n\n\n# Data Preparation\n\n## Making start and end dates compatible - \n```{r, echo=FALSE}\n#| output-location: slide\n\n#ts_real_estate_loans <- ts(real_estate_loans)\n#ts_mortgage_rate <- ts(mortgage_rate)\n\n# Get the start date\nloans_start_date <- min(real_estate_loans$date)\nmortgage_start_date <- min(mortgage_rate$date)\n\n# Get the end date\nloans_end_date <- max(real_estate_loans$date)\nmortgage_end_date <- max(mortgage_rate$date)\n\n# Print the start and end dates\n\nprint(paste(\"Start date of real estate loans series:\", loans_start_date))\nprint(paste(\"Start date of mortgage rate series:\", mortgage_start_date))\nprint(paste(\"End date of real estate loans series:\", loans_end_date))\nprint(paste(\"End date of mortgage rate series:\", mortgage_end_date))\n```\n\n<br> </br>\n```{r, echo=FALSE}\n#| output-location: slide\n# Subtracting one day from mortgage rate dataset to make it similar to real estate loans dataset\nmortgage_rate$date <- mortgage_rate$date - 1\n\n# Start date of real estate loans dataset is \"2004-06-02\", therefore, filtering out data before this date from mortgage rate series and end date should be \"2024-02-28\"\nfiltered_mortgae_rate <- mortgage_rate %>%\n  filter(date >=as.Date(\"2004-06-02\") & date <= as.Date(\"2024-02-28\"))\n\nfiltered_real_estate_loans <- real_estate_loans %>%\n  filter(date >=as.Date(\"2004-06-02\") & date <= as.Date(\"2024-02-28\"))\n\n\n# Get the start date\nloans_start_date <- min(filtered_real_estate_loans$date)\nmortgage_start_date <- min(filtered_mortgae_rate$date)\n\n# Get the end date\nloans_end_date <- max(filtered_real_estate_loans$date)\nmortgage_end_date <- max(filtered_mortgae_rate$date)\n\ncat(\"Start and end date of both the series after filtering the datasets - \")\nprint(paste(\"Start date of real estate loans series:\", loans_start_date))\nprint(paste(\"Start date of mortgage rate series:\", mortgage_start_date))\nprint(paste(\"End date of real estate loans series:\", loans_end_date))\nprint(paste(\"End date of mortgage rate series:\", mortgage_end_date))\n\n```\n\n## Number of observations after filteration - \n```{r, echo=FALSE}\n#| output-location: slide\ncat(\"- Total number of rows in real estate loans:\", nrow(filtered_real_estate_loans), \"\\n\")\ncat(\"- Total number of rows in mortgage rate:\", nrow(filtered_mortgae_rate), \"\\n\\n\")\n```\n\n\n\n# Data Analysis\n\n## Visualizing the datasets - \n```{r, echo=FALSE}\n#| output-location: slide\n\n# Plotting Real Estate Loans time-series data\nggplot(real_estate_loans, aes(x = date, y = value)) +\n  geom_line() +\n  labs(title = \"Time Series Plot of Real Estate Loans series\",\n       x = \"Date (Year)\",\n       y = \"value\")\n\n\n# Plotting Mortgage rate time-series data\nggplot(mortgage_rate, aes(x = date, y = value)) +\n  geom_line() +\n  labs(title = \"Time Series Plot of Mortgage rate series\",\n       x = \"Date (Year)\",\n       y = \"value\")\n```\n\n## Correlation coefficient - \n```{r, echo=FALSE}\n#| output-location: slide\nrealEstateLoan_mortgage_corr <- cor(filtered_real_estate_loans$value, filtered_mortgae_rate$value)\ncat(\"Correlation between Real Estate Loans and Mortgage rate series: \", realEstateLoan_mortgage_corr, \"\\n\")\n\n```\n\n## ACF and PACF of Real Estate loans - \n```{r, echo=FALSE}\n#| output-location: slide\n\n# Plotting ACF and PACF for filtered real estate loans series\nacf(filtered_real_estate_loans$value)\npacf(filtered_real_estate_loans$value)\n```\n\n## ACF and PACF of Mortgage Rate - \n```{r, echo=FALSE}\n#| output-location: slide\n\n# Plotting ACF and PACF for filtered mortgage rate series\nacf(filtered_mortgae_rate$value)\npacf(filtered_mortgae_rate$value)\n```\n\n## Decomposition for Real Estate Loans -  \n```{r, echo=FALSE}\n#| output-location: slide\n\nreal_estate_ts <- ts(filtered_real_estate_loans$value, frequency=52)\nreal_estate_decomp <- decompose(real_estate_ts, \"multiplicative\")\nplot(real_estate_decomp)\n\n```\n\n## Decomposition for Mortgage rate - \n```{r, echo=FALSE}\n#| output-location: slide\n\nmortgage_rate_ts <- ts(filtered_mortgae_rate$value, frequency=52)\nmortgage_rate_decomp <- decompose(mortgage_rate_ts, \"multiplicative\")\nplot(mortgage_rate_decomp)\n\n```\n\n## Plotting both the series - \n```{r}\n#| output-location: slide\n\nmin_max_scale <- function(x) {\n  (x - min(x)) / (max(x) - min(x))\n}\n\n# Scale the data for each series\nreal_estate_scaled <- filtered_real_estate_loans\nreal_estate_scaled$value <- min_max_scale(filtered_real_estate_loans$value)\n\nmortgage_scaled <- filtered_mortgae_rate\nmortgage_scaled$value <- min_max_scale(filtered_mortgae_rate$value)\n\n# Merge data\nmerged_data <- merge(real_estate_scaled, mortgage_scaled, by = \"date\", all = TRUE)\n\n# Plot series\nggplot(merged_data, aes(x = date)) +\n  geom_line(aes(y = value.x, color = \"Real Estate Loans\")) +\n  geom_line(aes(y = value.y, color = \"Mortgage Rate\")) +\n  labs(title = \"Weekly Series: Initial Jobless Claims vs Retail Sales\",\n       x = \"Date\",\n       y = \"Value\") +\n  scale_color_manual(name = \"Series\", values = c(\"Real Estate Loans\" = \"blue\", \"Mortgage Rate\" = \"red\")) +\n  theme_minimal()\n```\n\n## Checking for stationarity - \n```{r, echo=FALSE}\n#| output-location: slide\n\n# Function to check stationarity using ADF and KPSS tests\ncheck_stationarity <- function(data) {\n  adf_test <- adf.test(data)\n  kpss_test <- kpss.test(data)\n  \n  cat(\"ADF Test:\\n\")\n  print(adf_test)\n  cat(\"\\nKPSS Test:\\n\")\n  print(kpss_test)\n}\n\n# Function to make the data stationary by differencing\nmake_stationary <- function(data) {\n  diff_data <- diff(data)\n  return(diff_data)\n}\n\n# Assuming you have two dataframes: real_estate_data and mortgage_interest_data\n# Check stationarity for both series\ncat(\"Checking stationarity for Real Estate Loans: \")\ncheck_stationarity(filtered_real_estate_loans$value)\n```\n<br> </br>\n```{r, echo=FALSE}\n#| output-location: slide\n\ncat(\"Checking stationarity for Mortgage Rate: \")\ncheck_stationarity(filtered_mortgae_rate$value)\n```\n\n## Making data stationary:\n```{r, echo=FALSE}\n#| output-location: slide\n\n# Make the data stationary if necessary\nreal_estate_data_diff <- make_stationary(filtered_real_estate_loans$value)\nmortgage_interest_data_diff <- make_stationary(filtered_mortgae_rate$value)\n\n\n# Create a dataframe for differenced real estate data\nreal_estate_diff_df <- data.frame(date = filtered_real_estate_loans$date[-1], \n                                  diff_value = real_estate_data_diff)\n\n# Create a dataframe for differenced mortgage interest data\nmortgage_interest_diff_df <- data.frame(date = filtered_mortgae_rate$date[-1], \n                                        diff_value = mortgage_interest_data_diff)\n\n# Plot the differenced data to visually inspect stationarity\nggplot() +\n  geom_line(aes(x = date, y = diff_value), data = real_estate_diff_df, color = \"blue\") +\n  geom_line(aes(x = date, y = diff_value), data = mortgage_interest_diff_df, color = \"red\") +\n  labs(title = \"Differenced Data for Stationarity\",\n       x = \"Date\",\n       y = \"Differenced Value\",\n       color = \"Series\") +\n  theme_minimal()\n\n```\n\n\n\n# Modeling\n## Overview - regARIMA model\n- To model the complex relationship between residential real estate loans and mortgage rates, we employ a Regression with ARIMA errors (RegARIMA) model. \n- This approach allows for incorporating the average mortgage rate as an external regressor to predict the volume of real estate loans while accounting for auto-correlated residuals and non-stationarity inherent in time series data.\n\n## Mathematical framework\n\nThe RegARIMA model integrates regression analysis with ARIMA modeling, specified as:\n\n$$\ny_t = \\mathbf{X}_t \\boldsymbol{\\beta} + n_t\n$$\n\nwhere (y_t) is the observed time series at time (t), (\\mathbf{X}\\_t) represents external regressors, (\\boldsymbol{\\beta}) denotes the regression coefficients, and (n_t) is an error term following an ARIMA model:\n\n$$\n\\Phi(B) \\Delta^d n_t = \\Theta(B) \\epsilon_t\n$$\n\nHere, (\\Delta\\^d) is the differencing operator, (B) the backshift operator, (\\Phi(B)) and (\\Theta(B)) the AR and MA polynomial operators, and (\\epsilon\\_t) white noise.\n\n## Application in project\n- The goal is to analyze how the 30-Year Fixed Rate Mortgage Average impacts the volume of residential real estate loans.\n- To uncover the relationship between the volume of real estate loans and the average mortgage rate while accounting for autocorrelations within the residuals, we apply a RegARIMA modeling approach.\n- This section outlines the process from fitting a linear model to adjusting for ARIMA errors.\n\n## Summary of reg ARIMA model - \n```{r, echo=FALSE}\n#| output-location: slide\n\n# Regression Component\n# Include covariate series as a regressor in the ARIMA model\n# Fit regression ARIMA model\n#arima_model <- auto.arima(y = real_estate_diff_df$diff_value, xreg = mortgage_interest_diff_df$diff_value)\narima_model <- auto.arima(y = filtered_real_estate_loans$value, xreg = filtered_mortgae_rate$value)\nprint(summary(arima_model))\n```\n\n## Summary of reg ARIMA model - \n```{r, echo=FALSE}\ncat(\"- MAE is 6.88, which tells us the average absolute difference between the observed and predicted values. Lower MAE indicates better prediiction accuracy.\")\ncat(\"- MPE is positive, which tells us that the model is overestimating the predicted value than the actual value.\")\n```\n\n## Model equation - \n\n```{r, echo=FALSE}\ncat(\"Based on the provided coefficients, the regression ARIMA equation would be:\")\n\n```\n\n$$\ny_t = 1.1346 - 0.2217 \\cdot y_{t-1} - 0.2829 \\cdot y_{t-2} - 0.1260 \\cdot y_{t-3} + 0.2241 \\cdot y_{t-4} + 0.2442 \\cdot y_{t-5} + 0.1892 \\cdot e_{t-1} + 4.7569 \\cdot covariate + e_t\n$$\n\n\n## Model Diagnosis - \n```{r, echo=FALSE}\n#| output-location: slide\n\n# Diagnostic check of residuals\ncheckresiduals(arima_model)\n```\n\n## Model Diagnosis - \n```{r, echo=FALSE}\ncat(\"Residuals over time: \")\ncat(\"- Residuals fluctuate around the zero line, which is expected.\")\ncat(\"- There are several spikes that stand out, suggesting potential outliers or model misspecification.\")\ncat(\"- The variance of residuals appears constant over time, indicating no obvious signs of heteroscedasticity.\")\n```\n<br> </br>\n```{r, echo=FALSE}\ncat(\"Autocorrelation Function (ACF) of Residuals: \")\ncat(\"- The ACF plot does not show significant autocorrelations for any lag, as most of the bars are within the blue dashed confidence interval lines.\")\ncat(\"- This indicates that the residuals do not exhibit autocorrelation and the model is capturing the data's temporal structure well.\")\n```\n<br> </br>\n```{r, echo=FALSE}\ncat(\"Histogram and Density of Residuals: \")\ncat(\"- The histogram shows the distribution of residuals with a superimposed red line representing the normal distribution.\")\ncat(\"- Residuals are approximately normally distributed but show a slight leftward skew, suggesting a minor deviation from normality.\")\ncat(\"- Despite the skew, the distribution of residuals does not show extreme deviations from the expected normal distribution.\")\n```\n\n\n## Overview - VAR (Vector Autoregression) model\n- The Vector Autoregression (VAR) model is a type of time series model used for forecasting multiple time series variables simultaneously. \n- It extends the univariate autoregressive model to handle multiple time series variables that may interact with each other over time.\n\n\n## Mathematical framework - \n- VAR models are based on the assumption that each variable in the system is linearly dependent on its own lagged values as well as the lagged values of all other variables in the system.\n- Mathematically, a VAR(p) model of order p for k time series variables can be represented as:\n\nWhere:\n\nY<sub>t</sub> is a k-dimensional vector of endogenous variables at time t.\nC is a k-dimensional vector representing the intercept term.\nΦ<sub>1</sub>, Φ<sub>2</sub>, ..., Φ<sub>p</sub> are coefficient matrices of lagged values up to order p.\nU<sub>t</sub> is a k-dimensional vector of error terms at time t.\n\n## Summary of VAR model - \n```{r, echo=FALSE}\n#| output-location: slide\n\ncombined_data_for_var <- merge(filtered_real_estate_loans, filtered_mortgae_rate, by = \"date\", all = TRUE)\n\ncombined_data_for_var$date <- as.Date(combined_data_for_var$date)\ncombined_data_for_var <- na.omit(combined_data_for_var)\n\n\n# Convert the combined data to a time series object\nts_combined_data <- ts(combined_data_for_var[, c(\"value.x\", \"value.y\")], start = as.Date(\"2004-06-02\"), frequency = 52)\n\n# Create a VAR model\nvar_model <- VAR(ts_combined_data[, c(\"value.x\", \"value.y\")])\ncat(\"Summary of VAR model - \")\nprint(summary(var_model))\n\n```\n\n## Model diagnostics:\n```{r, echo=FALSE}\ncat(\"Root of the Characteristic Polynomial:\")\ncat(\"- The roots of the characteristic polynomial are provided. These roots are essential for understanding the stability of the model. In this case, the roots are 1.001 and 0.9943, indicating that the model is stable.\")\n```\n<br> </br>\n\n```{r, echo=FALSE}\ncat(\"Residual Analysis:\")\ncat(\"- Covariance matrix provides the covariance between residuals of each equation.\")\ncat(\"- t helps in understanding the linear relationship between the residuals of different equations.\")\ncat(\"- The RSE of 13.68 for house loans series means that, on average, the observed values of the endogenous variables deviate from the values predicted by the VAR model by approximately 13.68 units.\")\n```\n\n\n\n\n# Forecasting\n## regARIMA model - \n```{r, echo=FALSE}\n#| output-location: slide\n\n#arima_model <- auto.arima(y = filtered_real_estate_loans$value, xreg = filtered_mortgae_rate$value)\nreg_arima_forecast <- forecast(arima_model, xreg = filtered_mortgae_rate$value, h = 3)\nplot(reg_arima_forecast, main = \"Forecast for Real Estate Loans\")\n\n# Forecasting for the next week\nforecast_loans <- forecast(arima_model, xreg = tail(filtered_mortgae_rate$value, 1))\nregArima_forecast_value <- forecast_loans$mean[1]\n\ncat(\"\\nForecasted value for the next week:\", regArima_forecast_value)\n\n```\n\n## Cross-Validation - \n```{r, echo=FALSE}\n#| output-location: slide\n\n# 1. Prepare Data\n# Combine the two datasets by merging them based on the date column\ncombined_data <- merge(filtered_real_estate_loans, filtered_mortgae_rate, by = \"date\", all = TRUE)\n\n# 2. Cross-Validation Setup\nnum_folds <- 5  # Number of folds for cross-validation\nfold_size <- floor(nrow(combined_data) / num_folds)  # Size of each fold\n\n# Initialize vectors to store performance metrics for each time horizon\nrmse_values <- numeric(num_folds)\nmae_values <- numeric(num_folds)\nmape_values <- numeric(num_folds)\n\n# 3. Loop for Cross-Validation\nfor (i in 1:num_folds) {\n  # Determine the indices for the test set\n  test_indices <- ((i - 1) * fold_size + 1):(i * fold_size)\n\n  # Determine the indices for the training set\n  train_indices <- setdiff(1:nrow(combined_data), test_indices)\n\n  # Split the combined data into training and test sets for this fold\n  train_data <- combined_data[train_indices, ]\n  test_data <- combined_data[test_indices, ]\n\n  # Fit the regARIMA model using the training data\n  arima_model <- auto.arima(y = train_data$value.x, xreg = train_data$value.y)\n\n  # Generate forecasts for multiple time horizons using the fitted model\n  forecast_result <- forecast(arima_model, xreg = test_data$value.y, h = 1)\n\n  # Evaluate forecast accuracy for each time horizon\n  accuracy_metrics <- accuracy(forecast_result)\n  rmse_values[i] <- accuracy_metrics[1, 2]\n  mape_values[i] <- accuracy_metrics[1, \"MPE\"]\n  mae_values[i] <- accuracy_metrics[1, \"MAE\"]\n}\n\n# 4. Aggregate Results\nmean_rmse <- mean(rmse_values)\nmean_mae <- mean(mae_values)\nmean_mape <- mean(mape_values)\ncat(\"- RMSE value after cross validatiion: \", mean_rmse)\ncat(\"- MAE value after cross validatiion: \", mean_mae)\ncat(\"- MAPE value after cross validatiion: \", mean_mape)\n\n# Forecasting for the next week\nforecast_loans <- forecast(arima_model, xreg = tail(filtered_mortgae_rate$value, 1))\nregArima_forecast_value <- forecast_loans$mean[1]\n\ncat(\"\\nForecasted value for the next week:\", regArima_forecast_value)\ncat(\"\\n Forecasted value for regARIMA without cross validation has less error rate and thus final forecasted value for regARIMA model is: \", 2574.019)\n\n```\n\n## VAR model - \n```{r, echo=FALSE}\n#| output-location: slide\n\n# Forecast for a specific number of steps ahead\nnum_steps <- 52  # Adjust as needed\nvar_forecast <- predict(var_model, n.ahead = num_steps)\n\n# Plot the forecasts\nplot(var_forecast)\n```\n\n```{r, echo=FALSE}\n#| output-location: slide\n# Forecast for next week (1 step ahead)\nnext_week_forecast <- predict(var_model, n.ahead = 1)\n\n# Extract the forecasted values for the next week\nnext_week_forecast_values <- next_week_forecast$fcst[1]$value.x[1]\n\n# Print the forecasted values for the next week\ncat(\"\\nForecasted value for the next week:\", next_week_forecast_values)\n\n```\n\n## Cross-Validation -\n```{r, echo=FALSE}\n#| output-location: slide\n\n# 1. Prepare Data\n# Combine the two datasets by merging them based on the date column\ncombined_data_for_var_cv <- merge(filtered_real_estate_loans, filtered_mortgae_rate, by = \"date\", all = TRUE)\ncombined_data_for_var_cv <- na.omit(combined_data_for_var_cv)\n\n\n# train_size <- 0.8\n# n_obs <- nrow(combined_data_for_var)\n# train_index <- 1:round(train_size * n_obs)\n# test_index <- (round(train_size * n_obs) + 1):n_obs\n\n# Define the number of folds for cross-validation\nk <- 5\n\n# Initialize a vector to store evaluation metrics\nRMSE_values <- numeric(k)\nMAE_values <- numeric(k)\nMAPE_values <- numeric(k)\n\n\n# Perform k-fold cross-validation\nfor (i in 1:k) {\n  # Split data into training and testing sets for this fold\n  fold_train_index <- sample(1:nrow(combined_data_for_var_cv), size = round(0.8 * nrow(combined_data_for_var_cv)))\n  fold_test_index <- setdiff(1:nrow(combined_data_for_var_cv), fold_train_index)\n  \n  # Extract training and testing sets\n  train_data <- combined_data_for_var_cv[fold_train_index, ]\n  test_data <- combined_data_for_var_cv[fold_test_index, ]\n  \n  # Fit VAR model using training data\n  var_model_cv <- VAR(train_data[, c(\"value.x\", \"value.y\")], p = 2)\n  \n  # Forecast using VAR model\n  var_forecast_cv <- predict(var_model_cv, n.ahead = nrow(test_data))\n  \n  # Evaluate the forecast using RMSE\n  RMSE_values[i] <- sqrt(mean((var_forecast_cv$fcst$value.x - test_data$value.x)^2))\n  \n  # Calculate MAE for this fold\n  MAE_values[i] <- mean(abs(var_forecast_cv$fcst$value.x - test_data$value.x))\n  \n  # Calculate MAPE for this fold\n  MAPE_values[i] <- mean(abs((var_forecast_cv$fcst$value.x - test_data$value.x) / test_data$value.x)) * 100\n}\n\n# Mean RMSE across all folds\nmean_RMSE_cv <- mean(RMSE_values)\nmean_MAE_cv <- mean(MAE_values)\nmean_MAPE_cv <- mean(MAPE_values)\n\ncat(\"RMSE value for VAR model using cross validation: \", mean_RMSE_cv)\ncat(\"MAE value for VAR model using cross validation: \", mean_MAE_cv)\ncat(\"MAPE value for VAR model using cross validation: \", mean_MAPE_cv)\n\n# Forecast for next week (1 step ahead)\nnext_week_forecast_cv <- predict(var_model_cv, n.ahead = 1)\n\n# Extract the forecasted values for the next week\nnext_week_forecast_values_cv <- next_week_forecast_cv$fcst[1]$value.x[1]\n\n# Print the forecasted values for the next week\ncat(\"\\nForecasted value for the next week using cross validation:\", next_week_forecast_values_cv)\n\n\n```\n\n# Comparison\n## Error rates and forecasted values - \n```{r, echo=FALSE}\ncat(\"MAE value for regARIMA without cross-validation: 6.87518\")\ncat(\"MAE value for regARIMA with cross-validation: 8.950738\")\ncat(\"MAE for VAR without cross-validation: 13.68\")\ncat(\"MAE for VAR with cross-validation: 686.3736\")\n```\n<br> </br>\n\n```{r, echo=FALSE}\ncat(\"Forecasted value for regARIMA without cross-validation: 2574.019\")\ncat(\"Forecasted value for regARIMA with cross-validation: 2293.682\")\ncat(\"Forecasted for VAR without cross-validation: 2573.884\")\ncat(\"Forecasted for VAR with cross-validation: 2110.842\")\n```\n\n# Conclusion\n## Final forecasted value\nFinal forecasted value is chosen from regARIMA model without cross-validation: 2574.019\n\n\n## Practical Applications\n```{r, echo=FALSE}\ncat(\"- Lending Strategies: Banks can adjust their lending strategies based on predicted mortgage rate trends, optimizing interest rates to balance profit with risk.\")\ncat(\"- Risk Management: Predictions of loan volumes can inform risk assessments and capital reserve requirements to maintain financial stability.\")\ncat(\"- Market Analysis: Developers and real estate agencies can use these forecasts to anticipate market demand, informing decisions about when to build, sell, or market properties.\")\ncat(\"- Pricing Strategy: Accurate predictions of loans and interest rates can help set appropriate property pricing strategies to match market conditions.\")\n```\n\n","srcMarkdownNoYaml":"\n\n\n```{r, include=FALSE}\nlibrary(forecast)\nlibrary(fpp3)\nlibrary(tidyverse)\nlibrary(tsbox)\nlibrary(zoo)\nlibrary(seasonal)\nlibrary(astsa)\nlibrary(patchwork)\nlibrary(tseries)\nlibrary(fredr)\nlibrary(quarto)\nlibrary(xts)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(vars)\n\n```\n\n\n```{r setup, include=FALSE}\n# Set up chunk for all slides\nknitr::opts_chunk$set(\n  echo = TRUE,\n  message = FALSE,\n  warning = FALSE,\n  cache = TRUE,\n  dev.args = list(pointsize = 11)\n)\n```\n\n\n# Dataset\n\n## Time Series used in the project - \n- Real Estate Loans: \"Residential Real Estate Loans, All Commercial Banks\" from FRED which represents the total amount of residential real estate loans issued by all commercial banks in the United States.\n- The covariate series used is \"30-Year Fixed Rate Mortgage Average\" which represents the average interest rate on 30-year fixed-rate mortgages in the United States\n\n## Relevance - \n- The average interest rate on 30-year fixed-rate mortgages is a crucial factor influencing the affordability of home purchases and the demand for mortgage financing.\n- By analyzing trends in the fixed-rate mortgage average, we can gain insights into shifts in mortgage interest rates, which in turn can influence housing market activity, including home sales, and overall residential real estate lending.\n\n\n## Basic statistics about datasets - \n\n```{r, echo=FALSE}\n#| output-location: slide\n# Reading Real Estate Loans data and the covariate series Mortgage Rate\nfredr_set_key(\"4e2b405e7ea0d612c659d24c185134a1\")\n\nreal_estate_loans <- fredr(series_id = \"RREACBW027NBOG\")\nmortgage_rate <- fredr(series_id = \"MORTGAGE30US\")\n\n# Taking date and value column from booth the series\nreal_estate_loans <- real_estate_loans[c(\"date\", \"value\")]\nmortgage_rate <- mortgage_rate[c(\"date\", \"value\")]\n\n\n# Converting date column in both the series to date type\nreal_estate_loans$date <- as.Date(real_estate_loans$date)\nmortgage_rate$date <- as.Date(mortgage_rate$date)\n\ncat(\"- Both time series are on weekly basis and not seasonally adjusted.\\n\")\ncat(\"- Total number of rows in real estate loans dataset:\", nrow(real_estate_loans), \"\\n\")\ncat(\"- Total number of rows in mortgage rate dataset:\", nrow(mortgage_rate), \"\\n\\n\")\n\n# Basic summary statistics\ncat(\"- Summary of real estate loans dataset:\", \"\\n\")\nsummary(real_estate_loans)\n\ncat(\"- Summary of mortgage rate dataset:\", \"\\n\")\nsummary(mortgage_rate)\ncat(\"\\n\\n\")\n\n\n\n```\n\n\n\n# Data Preparation\n\n## Making start and end dates compatible - \n```{r, echo=FALSE}\n#| output-location: slide\n\n#ts_real_estate_loans <- ts(real_estate_loans)\n#ts_mortgage_rate <- ts(mortgage_rate)\n\n# Get the start date\nloans_start_date <- min(real_estate_loans$date)\nmortgage_start_date <- min(mortgage_rate$date)\n\n# Get the end date\nloans_end_date <- max(real_estate_loans$date)\nmortgage_end_date <- max(mortgage_rate$date)\n\n# Print the start and end dates\n\nprint(paste(\"Start date of real estate loans series:\", loans_start_date))\nprint(paste(\"Start date of mortgage rate series:\", mortgage_start_date))\nprint(paste(\"End date of real estate loans series:\", loans_end_date))\nprint(paste(\"End date of mortgage rate series:\", mortgage_end_date))\n```\n\n<br> </br>\n```{r, echo=FALSE}\n#| output-location: slide\n# Subtracting one day from mortgage rate dataset to make it similar to real estate loans dataset\nmortgage_rate$date <- mortgage_rate$date - 1\n\n# Start date of real estate loans dataset is \"2004-06-02\", therefore, filtering out data before this date from mortgage rate series and end date should be \"2024-02-28\"\nfiltered_mortgae_rate <- mortgage_rate %>%\n  filter(date >=as.Date(\"2004-06-02\") & date <= as.Date(\"2024-02-28\"))\n\nfiltered_real_estate_loans <- real_estate_loans %>%\n  filter(date >=as.Date(\"2004-06-02\") & date <= as.Date(\"2024-02-28\"))\n\n\n# Get the start date\nloans_start_date <- min(filtered_real_estate_loans$date)\nmortgage_start_date <- min(filtered_mortgae_rate$date)\n\n# Get the end date\nloans_end_date <- max(filtered_real_estate_loans$date)\nmortgage_end_date <- max(filtered_mortgae_rate$date)\n\ncat(\"Start and end date of both the series after filtering the datasets - \")\nprint(paste(\"Start date of real estate loans series:\", loans_start_date))\nprint(paste(\"Start date of mortgage rate series:\", mortgage_start_date))\nprint(paste(\"End date of real estate loans series:\", loans_end_date))\nprint(paste(\"End date of mortgage rate series:\", mortgage_end_date))\n\n```\n\n## Number of observations after filteration - \n```{r, echo=FALSE}\n#| output-location: slide\ncat(\"- Total number of rows in real estate loans:\", nrow(filtered_real_estate_loans), \"\\n\")\ncat(\"- Total number of rows in mortgage rate:\", nrow(filtered_mortgae_rate), \"\\n\\n\")\n```\n\n\n\n# Data Analysis\n\n## Visualizing the datasets - \n```{r, echo=FALSE}\n#| output-location: slide\n\n# Plotting Real Estate Loans time-series data\nggplot(real_estate_loans, aes(x = date, y = value)) +\n  geom_line() +\n  labs(title = \"Time Series Plot of Real Estate Loans series\",\n       x = \"Date (Year)\",\n       y = \"value\")\n\n\n# Plotting Mortgage rate time-series data\nggplot(mortgage_rate, aes(x = date, y = value)) +\n  geom_line() +\n  labs(title = \"Time Series Plot of Mortgage rate series\",\n       x = \"Date (Year)\",\n       y = \"value\")\n```\n\n## Correlation coefficient - \n```{r, echo=FALSE}\n#| output-location: slide\nrealEstateLoan_mortgage_corr <- cor(filtered_real_estate_loans$value, filtered_mortgae_rate$value)\ncat(\"Correlation between Real Estate Loans and Mortgage rate series: \", realEstateLoan_mortgage_corr, \"\\n\")\n\n```\n\n## ACF and PACF of Real Estate loans - \n```{r, echo=FALSE}\n#| output-location: slide\n\n# Plotting ACF and PACF for filtered real estate loans series\nacf(filtered_real_estate_loans$value)\npacf(filtered_real_estate_loans$value)\n```\n\n## ACF and PACF of Mortgage Rate - \n```{r, echo=FALSE}\n#| output-location: slide\n\n# Plotting ACF and PACF for filtered mortgage rate series\nacf(filtered_mortgae_rate$value)\npacf(filtered_mortgae_rate$value)\n```\n\n## Decomposition for Real Estate Loans -  \n```{r, echo=FALSE}\n#| output-location: slide\n\nreal_estate_ts <- ts(filtered_real_estate_loans$value, frequency=52)\nreal_estate_decomp <- decompose(real_estate_ts, \"multiplicative\")\nplot(real_estate_decomp)\n\n```\n\n## Decomposition for Mortgage rate - \n```{r, echo=FALSE}\n#| output-location: slide\n\nmortgage_rate_ts <- ts(filtered_mortgae_rate$value, frequency=52)\nmortgage_rate_decomp <- decompose(mortgage_rate_ts, \"multiplicative\")\nplot(mortgage_rate_decomp)\n\n```\n\n## Plotting both the series - \n```{r}\n#| output-location: slide\n\nmin_max_scale <- function(x) {\n  (x - min(x)) / (max(x) - min(x))\n}\n\n# Scale the data for each series\nreal_estate_scaled <- filtered_real_estate_loans\nreal_estate_scaled$value <- min_max_scale(filtered_real_estate_loans$value)\n\nmortgage_scaled <- filtered_mortgae_rate\nmortgage_scaled$value <- min_max_scale(filtered_mortgae_rate$value)\n\n# Merge data\nmerged_data <- merge(real_estate_scaled, mortgage_scaled, by = \"date\", all = TRUE)\n\n# Plot series\nggplot(merged_data, aes(x = date)) +\n  geom_line(aes(y = value.x, color = \"Real Estate Loans\")) +\n  geom_line(aes(y = value.y, color = \"Mortgage Rate\")) +\n  labs(title = \"Weekly Series: Initial Jobless Claims vs Retail Sales\",\n       x = \"Date\",\n       y = \"Value\") +\n  scale_color_manual(name = \"Series\", values = c(\"Real Estate Loans\" = \"blue\", \"Mortgage Rate\" = \"red\")) +\n  theme_minimal()\n```\n\n## Checking for stationarity - \n```{r, echo=FALSE}\n#| output-location: slide\n\n# Function to check stationarity using ADF and KPSS tests\ncheck_stationarity <- function(data) {\n  adf_test <- adf.test(data)\n  kpss_test <- kpss.test(data)\n  \n  cat(\"ADF Test:\\n\")\n  print(adf_test)\n  cat(\"\\nKPSS Test:\\n\")\n  print(kpss_test)\n}\n\n# Function to make the data stationary by differencing\nmake_stationary <- function(data) {\n  diff_data <- diff(data)\n  return(diff_data)\n}\n\n# Assuming you have two dataframes: real_estate_data and mortgage_interest_data\n# Check stationarity for both series\ncat(\"Checking stationarity for Real Estate Loans: \")\ncheck_stationarity(filtered_real_estate_loans$value)\n```\n<br> </br>\n```{r, echo=FALSE}\n#| output-location: slide\n\ncat(\"Checking stationarity for Mortgage Rate: \")\ncheck_stationarity(filtered_mortgae_rate$value)\n```\n\n## Making data stationary:\n```{r, echo=FALSE}\n#| output-location: slide\n\n# Make the data stationary if necessary\nreal_estate_data_diff <- make_stationary(filtered_real_estate_loans$value)\nmortgage_interest_data_diff <- make_stationary(filtered_mortgae_rate$value)\n\n\n# Create a dataframe for differenced real estate data\nreal_estate_diff_df <- data.frame(date = filtered_real_estate_loans$date[-1], \n                                  diff_value = real_estate_data_diff)\n\n# Create a dataframe for differenced mortgage interest data\nmortgage_interest_diff_df <- data.frame(date = filtered_mortgae_rate$date[-1], \n                                        diff_value = mortgage_interest_data_diff)\n\n# Plot the differenced data to visually inspect stationarity\nggplot() +\n  geom_line(aes(x = date, y = diff_value), data = real_estate_diff_df, color = \"blue\") +\n  geom_line(aes(x = date, y = diff_value), data = mortgage_interest_diff_df, color = \"red\") +\n  labs(title = \"Differenced Data for Stationarity\",\n       x = \"Date\",\n       y = \"Differenced Value\",\n       color = \"Series\") +\n  theme_minimal()\n\n```\n\n\n\n# Modeling\n## Overview - regARIMA model\n- To model the complex relationship between residential real estate loans and mortgage rates, we employ a Regression with ARIMA errors (RegARIMA) model. \n- This approach allows for incorporating the average mortgage rate as an external regressor to predict the volume of real estate loans while accounting for auto-correlated residuals and non-stationarity inherent in time series data.\n\n## Mathematical framework\n\nThe RegARIMA model integrates regression analysis with ARIMA modeling, specified as:\n\n$$\ny_t = \\mathbf{X}_t \\boldsymbol{\\beta} + n_t\n$$\n\nwhere (y_t) is the observed time series at time (t), (\\mathbf{X}\\_t) represents external regressors, (\\boldsymbol{\\beta}) denotes the regression coefficients, and (n_t) is an error term following an ARIMA model:\n\n$$\n\\Phi(B) \\Delta^d n_t = \\Theta(B) \\epsilon_t\n$$\n\nHere, (\\Delta\\^d) is the differencing operator, (B) the backshift operator, (\\Phi(B)) and (\\Theta(B)) the AR and MA polynomial operators, and (\\epsilon\\_t) white noise.\n\n## Application in project\n- The goal is to analyze how the 30-Year Fixed Rate Mortgage Average impacts the volume of residential real estate loans.\n- To uncover the relationship between the volume of real estate loans and the average mortgage rate while accounting for autocorrelations within the residuals, we apply a RegARIMA modeling approach.\n- This section outlines the process from fitting a linear model to adjusting for ARIMA errors.\n\n## Summary of reg ARIMA model - \n```{r, echo=FALSE}\n#| output-location: slide\n\n# Regression Component\n# Include covariate series as a regressor in the ARIMA model\n# Fit regression ARIMA model\n#arima_model <- auto.arima(y = real_estate_diff_df$diff_value, xreg = mortgage_interest_diff_df$diff_value)\narima_model <- auto.arima(y = filtered_real_estate_loans$value, xreg = filtered_mortgae_rate$value)\nprint(summary(arima_model))\n```\n\n## Summary of reg ARIMA model - \n```{r, echo=FALSE}\ncat(\"- MAE is 6.88, which tells us the average absolute difference between the observed and predicted values. Lower MAE indicates better prediiction accuracy.\")\ncat(\"- MPE is positive, which tells us that the model is overestimating the predicted value than the actual value.\")\n```\n\n## Model equation - \n\n```{r, echo=FALSE}\ncat(\"Based on the provided coefficients, the regression ARIMA equation would be:\")\n\n```\n\n$$\ny_t = 1.1346 - 0.2217 \\cdot y_{t-1} - 0.2829 \\cdot y_{t-2} - 0.1260 \\cdot y_{t-3} + 0.2241 \\cdot y_{t-4} + 0.2442 \\cdot y_{t-5} + 0.1892 \\cdot e_{t-1} + 4.7569 \\cdot covariate + e_t\n$$\n\n\n## Model Diagnosis - \n```{r, echo=FALSE}\n#| output-location: slide\n\n# Diagnostic check of residuals\ncheckresiduals(arima_model)\n```\n\n## Model Diagnosis - \n```{r, echo=FALSE}\ncat(\"Residuals over time: \")\ncat(\"- Residuals fluctuate around the zero line, which is expected.\")\ncat(\"- There are several spikes that stand out, suggesting potential outliers or model misspecification.\")\ncat(\"- The variance of residuals appears constant over time, indicating no obvious signs of heteroscedasticity.\")\n```\n<br> </br>\n```{r, echo=FALSE}\ncat(\"Autocorrelation Function (ACF) of Residuals: \")\ncat(\"- The ACF plot does not show significant autocorrelations for any lag, as most of the bars are within the blue dashed confidence interval lines.\")\ncat(\"- This indicates that the residuals do not exhibit autocorrelation and the model is capturing the data's temporal structure well.\")\n```\n<br> </br>\n```{r, echo=FALSE}\ncat(\"Histogram and Density of Residuals: \")\ncat(\"- The histogram shows the distribution of residuals with a superimposed red line representing the normal distribution.\")\ncat(\"- Residuals are approximately normally distributed but show a slight leftward skew, suggesting a minor deviation from normality.\")\ncat(\"- Despite the skew, the distribution of residuals does not show extreme deviations from the expected normal distribution.\")\n```\n\n\n## Overview - VAR (Vector Autoregression) model\n- The Vector Autoregression (VAR) model is a type of time series model used for forecasting multiple time series variables simultaneously. \n- It extends the univariate autoregressive model to handle multiple time series variables that may interact with each other over time.\n\n\n## Mathematical framework - \n- VAR models are based on the assumption that each variable in the system is linearly dependent on its own lagged values as well as the lagged values of all other variables in the system.\n- Mathematically, a VAR(p) model of order p for k time series variables can be represented as:\n\nWhere:\n\nY<sub>t</sub> is a k-dimensional vector of endogenous variables at time t.\nC is a k-dimensional vector representing the intercept term.\nΦ<sub>1</sub>, Φ<sub>2</sub>, ..., Φ<sub>p</sub> are coefficient matrices of lagged values up to order p.\nU<sub>t</sub> is a k-dimensional vector of error terms at time t.\n\n## Summary of VAR model - \n```{r, echo=FALSE}\n#| output-location: slide\n\ncombined_data_for_var <- merge(filtered_real_estate_loans, filtered_mortgae_rate, by = \"date\", all = TRUE)\n\ncombined_data_for_var$date <- as.Date(combined_data_for_var$date)\ncombined_data_for_var <- na.omit(combined_data_for_var)\n\n\n# Convert the combined data to a time series object\nts_combined_data <- ts(combined_data_for_var[, c(\"value.x\", \"value.y\")], start = as.Date(\"2004-06-02\"), frequency = 52)\n\n# Create a VAR model\nvar_model <- VAR(ts_combined_data[, c(\"value.x\", \"value.y\")])\ncat(\"Summary of VAR model - \")\nprint(summary(var_model))\n\n```\n\n## Model diagnostics:\n```{r, echo=FALSE}\ncat(\"Root of the Characteristic Polynomial:\")\ncat(\"- The roots of the characteristic polynomial are provided. These roots are essential for understanding the stability of the model. In this case, the roots are 1.001 and 0.9943, indicating that the model is stable.\")\n```\n<br> </br>\n\n```{r, echo=FALSE}\ncat(\"Residual Analysis:\")\ncat(\"- Covariance matrix provides the covariance between residuals of each equation.\")\ncat(\"- t helps in understanding the linear relationship between the residuals of different equations.\")\ncat(\"- The RSE of 13.68 for house loans series means that, on average, the observed values of the endogenous variables deviate from the values predicted by the VAR model by approximately 13.68 units.\")\n```\n\n\n\n\n# Forecasting\n## regARIMA model - \n```{r, echo=FALSE}\n#| output-location: slide\n\n#arima_model <- auto.arima(y = filtered_real_estate_loans$value, xreg = filtered_mortgae_rate$value)\nreg_arima_forecast <- forecast(arima_model, xreg = filtered_mortgae_rate$value, h = 3)\nplot(reg_arima_forecast, main = \"Forecast for Real Estate Loans\")\n\n# Forecasting for the next week\nforecast_loans <- forecast(arima_model, xreg = tail(filtered_mortgae_rate$value, 1))\nregArima_forecast_value <- forecast_loans$mean[1]\n\ncat(\"\\nForecasted value for the next week:\", regArima_forecast_value)\n\n```\n\n## Cross-Validation - \n```{r, echo=FALSE}\n#| output-location: slide\n\n# 1. Prepare Data\n# Combine the two datasets by merging them based on the date column\ncombined_data <- merge(filtered_real_estate_loans, filtered_mortgae_rate, by = \"date\", all = TRUE)\n\n# 2. Cross-Validation Setup\nnum_folds <- 5  # Number of folds for cross-validation\nfold_size <- floor(nrow(combined_data) / num_folds)  # Size of each fold\n\n# Initialize vectors to store performance metrics for each time horizon\nrmse_values <- numeric(num_folds)\nmae_values <- numeric(num_folds)\nmape_values <- numeric(num_folds)\n\n# 3. Loop for Cross-Validation\nfor (i in 1:num_folds) {\n  # Determine the indices for the test set\n  test_indices <- ((i - 1) * fold_size + 1):(i * fold_size)\n\n  # Determine the indices for the training set\n  train_indices <- setdiff(1:nrow(combined_data), test_indices)\n\n  # Split the combined data into training and test sets for this fold\n  train_data <- combined_data[train_indices, ]\n  test_data <- combined_data[test_indices, ]\n\n  # Fit the regARIMA model using the training data\n  arima_model <- auto.arima(y = train_data$value.x, xreg = train_data$value.y)\n\n  # Generate forecasts for multiple time horizons using the fitted model\n  forecast_result <- forecast(arima_model, xreg = test_data$value.y, h = 1)\n\n  # Evaluate forecast accuracy for each time horizon\n  accuracy_metrics <- accuracy(forecast_result)\n  rmse_values[i] <- accuracy_metrics[1, 2]\n  mape_values[i] <- accuracy_metrics[1, \"MPE\"]\n  mae_values[i] <- accuracy_metrics[1, \"MAE\"]\n}\n\n# 4. Aggregate Results\nmean_rmse <- mean(rmse_values)\nmean_mae <- mean(mae_values)\nmean_mape <- mean(mape_values)\ncat(\"- RMSE value after cross validatiion: \", mean_rmse)\ncat(\"- MAE value after cross validatiion: \", mean_mae)\ncat(\"- MAPE value after cross validatiion: \", mean_mape)\n\n# Forecasting for the next week\nforecast_loans <- forecast(arima_model, xreg = tail(filtered_mortgae_rate$value, 1))\nregArima_forecast_value <- forecast_loans$mean[1]\n\ncat(\"\\nForecasted value for the next week:\", regArima_forecast_value)\ncat(\"\\n Forecasted value for regARIMA without cross validation has less error rate and thus final forecasted value for regARIMA model is: \", 2574.019)\n\n```\n\n## VAR model - \n```{r, echo=FALSE}\n#| output-location: slide\n\n# Forecast for a specific number of steps ahead\nnum_steps <- 52  # Adjust as needed\nvar_forecast <- predict(var_model, n.ahead = num_steps)\n\n# Plot the forecasts\nplot(var_forecast)\n```\n\n```{r, echo=FALSE}\n#| output-location: slide\n# Forecast for next week (1 step ahead)\nnext_week_forecast <- predict(var_model, n.ahead = 1)\n\n# Extract the forecasted values for the next week\nnext_week_forecast_values <- next_week_forecast$fcst[1]$value.x[1]\n\n# Print the forecasted values for the next week\ncat(\"\\nForecasted value for the next week:\", next_week_forecast_values)\n\n```\n\n## Cross-Validation -\n```{r, echo=FALSE}\n#| output-location: slide\n\n# 1. Prepare Data\n# Combine the two datasets by merging them based on the date column\ncombined_data_for_var_cv <- merge(filtered_real_estate_loans, filtered_mortgae_rate, by = \"date\", all = TRUE)\ncombined_data_for_var_cv <- na.omit(combined_data_for_var_cv)\n\n\n# train_size <- 0.8\n# n_obs <- nrow(combined_data_for_var)\n# train_index <- 1:round(train_size * n_obs)\n# test_index <- (round(train_size * n_obs) + 1):n_obs\n\n# Define the number of folds for cross-validation\nk <- 5\n\n# Initialize a vector to store evaluation metrics\nRMSE_values <- numeric(k)\nMAE_values <- numeric(k)\nMAPE_values <- numeric(k)\n\n\n# Perform k-fold cross-validation\nfor (i in 1:k) {\n  # Split data into training and testing sets for this fold\n  fold_train_index <- sample(1:nrow(combined_data_for_var_cv), size = round(0.8 * nrow(combined_data_for_var_cv)))\n  fold_test_index <- setdiff(1:nrow(combined_data_for_var_cv), fold_train_index)\n  \n  # Extract training and testing sets\n  train_data <- combined_data_for_var_cv[fold_train_index, ]\n  test_data <- combined_data_for_var_cv[fold_test_index, ]\n  \n  # Fit VAR model using training data\n  var_model_cv <- VAR(train_data[, c(\"value.x\", \"value.y\")], p = 2)\n  \n  # Forecast using VAR model\n  var_forecast_cv <- predict(var_model_cv, n.ahead = nrow(test_data))\n  \n  # Evaluate the forecast using RMSE\n  RMSE_values[i] <- sqrt(mean((var_forecast_cv$fcst$value.x - test_data$value.x)^2))\n  \n  # Calculate MAE for this fold\n  MAE_values[i] <- mean(abs(var_forecast_cv$fcst$value.x - test_data$value.x))\n  \n  # Calculate MAPE for this fold\n  MAPE_values[i] <- mean(abs((var_forecast_cv$fcst$value.x - test_data$value.x) / test_data$value.x)) * 100\n}\n\n# Mean RMSE across all folds\nmean_RMSE_cv <- mean(RMSE_values)\nmean_MAE_cv <- mean(MAE_values)\nmean_MAPE_cv <- mean(MAPE_values)\n\ncat(\"RMSE value for VAR model using cross validation: \", mean_RMSE_cv)\ncat(\"MAE value for VAR model using cross validation: \", mean_MAE_cv)\ncat(\"MAPE value for VAR model using cross validation: \", mean_MAPE_cv)\n\n# Forecast for next week (1 step ahead)\nnext_week_forecast_cv <- predict(var_model_cv, n.ahead = 1)\n\n# Extract the forecasted values for the next week\nnext_week_forecast_values_cv <- next_week_forecast_cv$fcst[1]$value.x[1]\n\n# Print the forecasted values for the next week\ncat(\"\\nForecasted value for the next week using cross validation:\", next_week_forecast_values_cv)\n\n\n```\n\n# Comparison\n## Error rates and forecasted values - \n```{r, echo=FALSE}\ncat(\"MAE value for regARIMA without cross-validation: 6.87518\")\ncat(\"MAE value for regARIMA with cross-validation: 8.950738\")\ncat(\"MAE for VAR without cross-validation: 13.68\")\ncat(\"MAE for VAR with cross-validation: 686.3736\")\n```\n<br> </br>\n\n```{r, echo=FALSE}\ncat(\"Forecasted value for regARIMA without cross-validation: 2574.019\")\ncat(\"Forecasted value for regARIMA with cross-validation: 2293.682\")\ncat(\"Forecasted for VAR without cross-validation: 2573.884\")\ncat(\"Forecasted for VAR with cross-validation: 2110.842\")\n```\n\n# Conclusion\n## Final forecasted value\nFinal forecasted value is chosen from regARIMA model without cross-validation: 2574.019\n\n\n## Practical Applications\n```{r, echo=FALSE}\ncat(\"- Lending Strategies: Banks can adjust their lending strategies based on predicted mortgage rate trends, optimizing interest rates to balance profit with risk.\")\ncat(\"- Risk Management: Predictions of loan volumes can inform risk assessments and capital reserve requirements to maintain financial stability.\")\ncat(\"- Market Analysis: Developers and real estate agencies can use these forecasts to anticipate market demand, informing decisions about when to build, sell, or market properties.\")\ncat(\"- Pricing Strategy: Accurate predictions of loans and interest rates can help set appropriate property pricing strategies to match market conditions.\")\n```\n\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","toc":true,"toc-depth":1,"output-file":"project_1.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.3.450","auto-stretch":true,"title":"Time Series - Midterm Project","subtitle":"Residential Real Estate Financing Patterns: Insights from Mortgage Averages","author":"By - Sree Lekshmi Prasannan <br> Jaskirat Singh","editor":"source","slideNumber":true,"smaller":false,"scrollable":true,"editor_options":{"chunk_output_type":"console"},"output-dir":"docs"}}},"projectFormats":["html"]}